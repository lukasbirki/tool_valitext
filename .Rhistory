remotes::install_github("paleolimbot/rbbt")
library(rbbt)
bbt_update_bib()
Validation is a necessary requirement for computational text analysis [@grimmer2013text]. Essentially, the purpose of validation is to ensure that what is to be measured is actually measured. In the context of computational text analysis, this means that ensuring that the models output scores are an accurate reflection of the true nature of the construct being studied.
#| echo: false
#| output: asis
# Dummy data for the first tab
dummy_data_1 <- data.frame(
Name = c("Alice", "Bob", "Charlie"),
Age = c(23, 30, 25),
Occupation = c("Engineer", "Doctor", "Artist")
)
# Dummy data for the second tab
dummy_data_2 <- data.frame(
Country = c("USA", "Germany", "Japan"),
Population = c(331000000, 83000000, 125800000),
Continent = c("North America", "Europe", "Asia")
)
# First tab content
cat("\n## Framework")
div(tags$img(src = "www/checklist.png", id = "myimagecheck", style = "margin-top: 40px;margin-bottom: 40px; cursor: pointer;"),
p(class = "caption", "Figure 2: Screenshot Checklist (click to expand)"))
#| echo: false
#| output: asis
# Dummy data for the first tab
dummy_data_1 <- data.frame(
Name = c("Alice", "Bob", "Charlie"),
Age = c(23, 30, 25),
Occupation = c("Engineer", "Doctor", "Artist")
)
# Dummy data for the second tab
dummy_data_2 <- data.frame(
Country = c("USA", "Germany", "Japan"),
Population = c(331000000, 83000000, 125800000),
Continent = c("North America", "Europe", "Asia")
)
# First tab content
cat("\n## Framework")
![Framework](images/framework.png)
Do demonstrate external evidence, @samory2021call primarily rely on the comparison of measures with a human-annotated test set (III.1). To calculate classification performance, they apply k-fold cross-validation and report F1 scores. The evaluation of F1 score is widely regarded as the most viable metric, as alternative metrics such as accuracy (i.e., the overall ratio of positive predictions) can be misleading when dealing with imbalanced data [@spelmen2018review].
